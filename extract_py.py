# -*- coding: utf-8 -*-
"""extract.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PD-JhimHJ86tBDHxD5SmWCrcb7upk0dZ
"""



import pandas as pd
from dateutil import parser
from googleapiclient.discovery import build

class Extract():
    def _init_(self):
        # Initialize variables.
        self.api_service_name = 'youtube'
        self.api_version = 'v3'
        self.api_key = 'AIzaSyBfsz13OHhGI51aPMASG4NtfmM4EBbWyDY'
        self.channel_id = 'UCZGYJFUizSax-yElQaFDp5Q' @starwars channel id
        self.youtube = build(self.api_service_name, self.api_version, developerKey=self.api_key)
    
    def get_channel_info(self):
        # Get the channel information
        channel_response = self.youtube.channels().list(
            part='snippet',
            id=self.channel_id
        )
        channel_response = channel_response.execute()
        
        return(channel_response)
    
    def get_videos_list(self):
        # Receive @starwars channel info.
        channel_response = self.get_channel_info()
        
        # Extract the channel creation date
        channel_created = channel_response['items'][0]['snippet']['publishedAt']
        channel_created_date = parser.parse(channel_created)
        
        # Define the search query parameters
        # Find videos that contain 'Trailer'.
        query = 'Trailer'
        # Number of videos to retrieve per code execution.
        num_results = 5 
        # All videos published after @starwars' YouTube channel conception.
        published_after = channel_created_date.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        # Call the YouTube Data API to retrieve the list of videos.
        search_response = self.youtube.search().list(
            part='id,snippet',
            channelId=self.channel_id,
            q=query,
            type='video',
            maxResults=num_results,
            publishedAfter=published_after
        )
        search_response = search_response.execute()
        
        return(search_response)
    
    def get_comments(self):
        videos_info_list = self.get_videos_list()
        
        # Extract the video ids and titles from the API response
        video_ids = []
        video_titles = []
        for info in videos_info_list.get('items', []):
            video_ids.append(info['id']['videoId'])
            video_titles.append(info['snippet']['title'])
            
        # Call the YouTube Data API to retrieve comments for the videos.
        comments = []
        for video_id, video_title in zip(video_ids, video_titles):
            results = self.youtube.commentThreads().list(
                part='snippet',
                videoId=video_id,
                textFormat='plainText',
                maxResults=10
            )
            results = results.execute()
            
            while results:
                for item in results['items']:
                    comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
                    author = item['snippet']['topLevelComment']['snippet']['authorDisplayName']
                    date = item['snippet']['topLevelComment']['snippet']['publishedAt']
                    comments.append([video_title, author, comment, date])

                    # Stop after 1000 comments have been collected
                    if len(comments) == 50:
                        break

                if len(comments) == 50:
                    break
                
        # Convert the list of comments to a pandas DataFrame
        df_comments = pd.DataFrame(comments, columns=['video_title', 'author', 'comment', 'date'])
        
        return(df_comments)